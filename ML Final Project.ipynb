{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0adb00d2",
   "metadata": {},
   "source": [
    "# ML Final Project\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0622e3",
   "metadata": {},
   "source": [
    "### Shruti Kotha, Mia Tey, Jeni Pham, and Shruti Patel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "867e31cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[133], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Counter\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "#add imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bae3246",
   "metadata": {},
   "source": [
    "## Final Project Objective: \n",
    "We can use the features (age, breed, color, animal, sex upon outcome, outcome subtype,\n",
    "name) to predict outcome (Foster, Adoption, Transfer, Euthanize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3b313e",
   "metadata": {},
   "source": [
    "### Part 1. Data Preperation for Modeling\n",
    "\n",
    "For this part of the assignment we read in our data and will perform various data prep techniques like data cleaning and feature engineering to prepare our data for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8bdfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('animaloutcomes.csv', skipinitialspace = True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4778e330",
   "metadata": {},
   "source": [
    "#### Data cleaning\n",
    "\n",
    "View the distribution of \"Outcome Type\". We want to ensure there is sufficient data for each \"Outcome Type\" and if there isn't we can drop columns as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87958c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_counts = data['Outcome Type'].value_counts()\n",
    "print(outcome_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5370c6",
   "metadata": {},
   "source": [
    "First, our label column will be \"Outcome Type\", since that is what we want to predict. \n",
    "If there are any records that lack an entry for \"Outcome Type\" we drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e153ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Length before droping Outcome Type: \", len(data['Outcome Type']))\n",
    "data = data.dropna(subset=['Outcome Type'])\n",
    "print(\"Length after drop Outcome Type: \", len(data['Outcome Type']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df7ca72",
   "metadata": {},
   "source": [
    "Second, we want to drop \"Outcome Subtype\". Since most rows have NaN in the \"Outcome Subtype\" column, it won't be an important column for us to use in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfcfc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['Outcome Subtype', 'Name', 'DateTime', 'Date of Birth', 'Animal ID'], inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f4fae9",
   "metadata": {},
   "source": [
    "It looks like there are no missing values for 'Outcome Type' anymore... Great!\n",
    "\n",
    "TODO: delete this\n",
    "\n",
    "Looking at the names column, there are a lot of blank entries for names. For the purposes of testing, we are\n",
    "going to test with both dropping the names column and keeping it. \n",
    "First, let's see how many blank entries there are.\n",
    "Second, create a temporary dataset that drops records with N/A for name. Later, we will see if accuracy is better or worse with the version that drops null name entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622ebdd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# total_null =  data[\"Name\"].isnull().sum()\n",
    "# print(\"Total missing values in 'Name' col before drop: \", total_null)\n",
    "# print(\"Ratio of total records with N/A for 'Name': \", total_null/len(data[\"Name\"]), \"\\n\")\n",
    "\n",
    "# # Create a temporary dataset that drops records with N/A for name\n",
    "# temp_drop_data = data.dropna(subset=['Name'])\n",
    "# # Verify we dropped the null records\n",
    "# total_null =  temp_drop_data[\"Name\"].isnull().sum()\n",
    "# print(\"Total missing values in 'Name' col after drop: \", total_null)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5753a19d",
   "metadata": {},
   "source": [
    "As for the colors, since we plan on using them for our models later, we should simplify the categories, as there are way too many unique categories for testing.\n",
    "First, there are entries such as 'black/white' and 'white/black' let's combine these into one label.\n",
    "Second, there are a lot of unique combinations of two colors. For these records whose combination of color makes up <5% of all colors, add these into one column called 'Multicolor' and jointly categorize it with the 'Tricolor' attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc59ee4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine categories such as 'black/white' and 'white/black'\n",
    "def join_same_color(color):\n",
    "    color_components = color.split('/')\n",
    "    color_components.sort()\n",
    "    return '/'.join(color_components)\n",
    "data['Color'] = data['Color'].apply(join_same_color)\n",
    "\n",
    "\n",
    "# Create Multicolor category \n",
    "color_counts = data['Color'].value_counts()\n",
    "color_percent = color_counts / color_counts.sum() * 100\n",
    "less_than_5_percent = color_percent[color_percent < 1].index\n",
    "data['Color'] = data['Color'].apply(lambda x: 'Multicolor' if x in less_than_5_percent or x == 'Tricolor' else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d68166",
   "metadata": {},
   "source": [
    "Create new column for seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a88081",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_season(month):\n",
    "    if month in [3, 4, 5]:\n",
    "        return 'Spring'\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 'Summer'\n",
    "    elif month in [9, 10, 11]:\n",
    "        return 'Fall'\n",
    "    else:\n",
    "        return 'Winter'\n",
    "    \n",
    "data['Month'] = pd.to_datetime(data['MonthYear'], format='%b %Y').dt.month\n",
    "data['Season'] = data['Month'].apply(get_season)\n",
    "data = data.drop('Month', axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed70a63b",
   "metadata": {},
   "source": [
    "We'll be categorizing the various breeds in the dataset. https://www.trainpetdog.com/dog-breed-size-chart/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38200fd2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# only keep records that are Dogs\n",
    "records_to_keep = ['Dog']\n",
    "dog_data = data[data['Animal Type'].isin(records_to_keep)]\n",
    "\n",
    "# only keep top 100 most frequent dog breeds in dataset\n",
    "top_100_breeds = dog_data['Breed'].value_counts().head(100).index\n",
    "breeds_data = dog_data[dog_data['Breed'].isin(top_100_breeds)]\n",
    "breeds_data = breeds_data.copy()\n",
    "\n",
    "# print(top_100_breeds)\n",
    "\n",
    "\n",
    "\n",
    "# large 70 + lbs avg, small, medium\n",
    "breed_to_category = {\n",
    "    'Pit Bull Mix': 'Medium/Large Breeds',\n",
    "    'Labrador Retriever Mix': 'Medium/Large Breeds',\n",
    "    'Chihuahua Shorthair Mix': 'Small Breeds',\n",
    "    'German Shepherd Mix': 'Medium/Large Breeds',\n",
    "    'Pit Bull': 'Medium/Large Breeds',\n",
    "    'Australian Cattle Dog Mix': 'Medium/Large Breeds',\n",
    "    'Chihuahua Shorthair': 'Small Breeds',\n",
    "    'Labrador Retriever': 'Medium/Large Breeds',\n",
    "    'German Shepherd': 'Medium/Large Breeds',\n",
    "    'Dachshund Mix': 'Medium/Small Breeds', \n",
    "    'Boxer Mix': 'Medium/Large Breeds',\n",
    "    'Border Collie Mix': 'Medium/Large Breeds',\n",
    "    'Miniature Poodle Mix': 'Small Breeds',\n",
    "    'Siberian Husky Mix': 'Medium Breeds',\n",
    "    'Australian Shepherd Mix': 'Medium/Large Breeds',\n",
    "    'Catahoula Mix': 'Medium/Large Breeds',\n",
    "    'Staffordshire Mix': 'Medium/Large Breeds',\n",
    "    'Siberian Husky': 'Medium Breeds',\n",
    "    'Rat Terrier Mix': 'Small Breeds',\n",
    "    'Great Pyrenees Mix': 'Large Breeds',\n",
    "    'Yorkshire Terrier Mix': 'Small Breeds',\n",
    "    'Beagle Mix': 'Medium/Large Breeds',\n",
    "    'Miniature Schnauzer Mix': 'Medium/Small Breeds',\n",
    "    'Jack Russell Terrier Mix': 'Medium/Small Breeds',\n",
    "    'Pointer Mix': 'Large Breeds',\n",
    "    'Cairn Terrier Mix' : 'Small Breeds',\n",
    "    'American Bulldog Mix': 'Medium/Large Breeds',                      \n",
    "    'Chihuahua Longhair Mix': 'Small Breeds',   \n",
    "    'Anatol Shepherd Mix': 'Medium/Large Breeds',\n",
    "    'Rottweiler Mix': 'Medium/Large Breeds',\n",
    "    'Australian Cattle Dog': 'Medium Breeds',\n",
    "    'Black Mouth Cur Mix': 'Medium/Large Breeds',\n",
    "    'Plott Hound Mix': 'Medium/Large Breeds',\n",
    "    'Labrador Retriever/Pit Bull': 'Medium/Large Breeds',\n",
    "    'Australian Kelpie Mix': 'Medium Breeds',\n",
    "    'Shih Tzu Mix': 'Small Breeds',\n",
    "    'Chihuahua Shorthair/Dachshund': 'Small Breeds',\n",
    "    'Great Pyrenees': 'Large Breeds',\n",
    "    'American Pit Bull Terrier Mix': 'Medium/Large Breeds',\n",
    "    'German Shepherd/Labrador Retriever': 'Large Breeds',\n",
    "    'Dachshund/Chihuahua Shorthair': 'Small Breeds',\n",
    "    'Labrador Retriever/German Shepherd': 'Large Breeds',\n",
    "    'American Staffordshire Terrier Mix': 'Medium/Large Breeds',\n",
    "    'Rottweiler': 'Large Breeds',\n",
    "    'Boxer': 'Medium/Large Breeds',\n",
    "    'Shih Tzu': 'Small Breeds',\n",
    "    'Pit Bull/Labrador Retriever': 'Medium/Large Breeds',\n",
    "    'Dachshund': 'Small Breeds',\n",
    "    'Golden Retriever Mix': 'Large Breeds',\n",
    "    'Maltese Mix': 'Small Breeds',\n",
    "    'Border Terrier Mix': 'Small Breeds',\n",
    "    'Miniature Pinscher Mix': 'Small Breeds',\n",
    "    'Yorkshire Terrier': 'Small Breeds',\n",
    "    'Blue Lacy Mix': 'Medium/Large Breeds',\n",
    "    'Doberman Pinsch Mix': 'Medium/Large Breeds',\n",
    "    'Miniature Poodle': 'Small Breeds',\n",
    "    'Chow Chow Mix': 'Medium/Large Breeds',\n",
    "    'American Pit Bull Terrier': 'Medium/Large Breeds',\n",
    "    'Cairn Terrier': 'Small Breeds',\n",
    "    'Border Collie': 'Medium/Large Breeds',\n",
    "    'Queensland Heeler Mix': 'Medium Breeds',\n",
    "    'Doberman Pinsch': 'Medium/Large Breeds',\n",
    "    'Basset Hound Mix': 'Medium/Large Breeds',\n",
    "    'Labrador Retriever/Border Collie': 'Large Breeds',\n",
    "    'Alaskan Husky Mix': 'Medium/Large Breeds',\n",
    "    'Pug Mix': 'Small Breeds',\n",
    "    'Beagle': 'Small Breeds',\n",
    "    'Pomeranian Mix': 'Small Breeds',\n",
    "    'Mastiff Mix': 'Large Breeds',\n",
    "    'Cocker Spaniel Mix': 'Small Breeds',\n",
    "    'Cardigan Welsh Corgi Mix': 'Medium Breeds',\n",
    "    'Miniature Schnauzer': 'Small Breeds',\n",
    "    'Lhasa Apso Mix': 'Small Breeds',\n",
    "    'Chinese Sharpei Mix': 'Medium/Large Breeds',\n",
    "    'Australian Shepherd': 'Medium/Large Breeds',\n",
    "    'Labrador Retriever/Australian Cattle Dog': 'Medium/Large Breeds',\n",
    "    'Black/Tan Hound Mix': 'Medium/Large Breeds',\n",
    "    'Pug': 'Small Breeds',\n",
    "    'Chihuahua Longhair': 'Small Breeds',\n",
    "    'Great Dane Mix': 'Large Breeds',\n",
    "    'Boston Terrier Mix': 'Small Breeds',\n",
    "    'Border Collie/Labrador Retriever': 'Large Breeds',\n",
    "    'Labrador Retriever/Great Pyrenees' : 'Large Breeds',\n",
    "    'Dachshund Wirehair Mix' : 'Small Breeds',\n",
    "    'Dachshund Longhair Mix' : 'Small Breeds',\n",
    "    'Alaskan Husky' : 'Medium/Large Breeds',\n",
    "    'Flat Coat Retriever Mix' : 'Large Breeds',\n",
    "    'Manchester Terrier Mix' : 'Small Breeds',\n",
    "    'Toy Poodle Mix' : 'Small Breeds',\n",
    "    'American Bulldog' : 'Medium/Large Breeds',\n",
    "    'Rat Terrier' : 'Small Breeds',\n",
    "    'Collie Smooth Mix' : 'Medium/Large Breeds',\n",
    "    'Maltese' : 'Small Breeds',\n",
    "    'Anatol Shepherd' : 'Medium/Large Breeds',\n",
    "    'Staffordshire' : 'Medium/Large Breeds',\n",
    "    'Belgian Malinois Mix' : 'Medium/Large Breeds',\n",
    "    'Pit Bull/Boxer' : 'Medium/Large Breeds',\n",
    "    'Norfolk Terrier Mix' : 'Small Breeds',\n",
    "    'Australian Cattle Dog/Labrador Retriever' : 'Medium/Large Breeds',\n",
    "    'Rhod Ridgeback Mix' : 'Large Breeds'         \n",
    "}\n",
    "print()\n",
    "print(\"Distribution based on size of breed:\")\n",
    "\n",
    "categories = [breed_to_category.get(breed) for breed in breeds_data['Breed']]\n",
    "\n",
    "category_counts = Counter(categories)\n",
    "\n",
    "for category, count in category_counts.items():\n",
    "    print(f'{category}: {count}')\n",
    "\n",
    "# to do add a size category with the breed to wsize mapping\n",
    "breeds_data.loc[:, 'Size'] = breeds_data['Breed'].map(breed_to_category)\n",
    "dog_data = breeds_data\n",
    "# dog_data[\"Breed\"] = dog_data[\"Size\"]\n",
    "\n",
    "# print(len(dog_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bf8073",
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0394fb8f",
   "metadata": {},
   "source": [
    "#### Graphing Data Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77a17ee",
   "metadata": {},
   "source": [
    "We will be graphing data distributions as part of data exploration. We will be looking for any imbalances, outliers, or anything that could potentially skeww the results of our data. We will then correct that before modeling.\n",
    "\n",
    "Plot distribution of colors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661ef458",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_counts = dog_data['Color'].value_counts()\n",
    "color_counts.plot(kind='pie', autopct='%1.1f%%')\n",
    "plt.title('Distribution of Colors')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ceb18d3",
   "metadata": {},
   "source": [
    "Display of distribution of season and outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb3fee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "season_counts = dog_data['Season'].value_counts()\n",
    "season_counts.plot(kind='bar')\n",
    "plt.title('Frequency of Seasons within dataset')\n",
    "plt.xlabel('Season')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=0)  \n",
    "plt.show()\n",
    "\n",
    "outcome_by_season = pd.crosstab(dog_data['Season'], dog_data['Outcome Type'])\n",
    "outcome_by_season.plot(kind='bar', stacked=True)\n",
    "plt.title('Outcomes by Season')\n",
    "plt.xlabel('Season')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=0)  \n",
    "plt.legend(loc='upper right', bbox_to_anchor=(1.5, 1))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bee290f",
   "metadata": {},
   "source": [
    "Distribution of dog breed sizes for the top 100 breeds in the dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e4789c",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_labels = [label for label, value in category_counts.items() if label is not None]\n",
    "category_values = [value for label, value in category_counts.items() if label is not None]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(category_labels, category_values)\n",
    "plt.title('Distribution of Dog Breeds by Category')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7e0827",
   "metadata": {},
   "source": [
    "Distribution of dog sex upon Outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8139a0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_upon_outcome = dog_data[\"Sex upon Outcome\"]\n",
    "\n",
    "male = 0\n",
    "female = 0\n",
    "\n",
    "for outcome in sex_upon_outcome:\n",
    "    if pd.notna(outcome):\n",
    "        if \"Male\" in outcome:\n",
    "            male += 1\n",
    "        elif \"Female\" in outcome:\n",
    "            female += 1\n",
    "\n",
    "        \n",
    "categories = [\"Male\", \"Female\"]\n",
    "counts = [male, female]\n",
    "\n",
    "plt.bar(categories, counts)\n",
    "plt.title(\"Distribution of Male and Female\")\n",
    "plt.xlabel(\"Sex\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Number of Males: {male}\")\n",
    "print(f\"Number of Females: {female}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ceaef69",
   "metadata": {},
   "source": [
    "Distrubtion of nuetured vs spayed at outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999da4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "neutered = 0\n",
    "spayed = 0\n",
    "intact = 0\n",
    "\n",
    "sex_counts = dog_data[\"Sex upon Outcome\"].value_counts()\n",
    "print(sex_counts)\n",
    "\n",
    "for outcome in sex_upon_outcome:\n",
    "    if pd.notna(outcome):\n",
    "        if \"Neutered\" in outcome:\n",
    "            neutered += 1\n",
    "        elif \"Spayed\" in outcome:\n",
    "            spayed += 1\n",
    "        elif \"Intact\" in outcome: \n",
    "            intact += 1\n",
    "        \n",
    "categories = [\"Neutered\", \"Spayed\", \"Intact\"]\n",
    "counts = [neutered, spayed, intact]\n",
    "\n",
    "plt.bar(categories, counts)\n",
    "plt.title(\"Distribution of Neutered, Spayed, or Intact\")\n",
    "plt.xlabel(\"Sterilization Status\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Number of Neutered: {neutered}\")\n",
    "print(f\"Number of Spayed: {spayed}\")\n",
    "print(f\"Number of Intact: {intact}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d442544",
   "metadata": {},
   "source": [
    "Distribution of Months when animals were registered (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63657884",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_data = dog_data['MonthYear']\n",
    "df = pd.DataFrame(month_data)\n",
    "pattern = r'([a-zA-Z]{3}) \\d{4}'\n",
    "df['MonthYear'] = df['MonthYear'].str.extract(pattern)\n",
    "# print(df)\n",
    "data.head()\n",
    "month_order = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "month_counts = df['MonthYear'].value_counts()\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=month_counts.index, y=month_counts.values, order=month_order)\n",
    "plt.title('Distribution of Months')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2c206a",
   "metadata": {},
   "source": [
    "Convert the age upon outcome into months and then plot the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc53045",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_months(age_str):\n",
    "    # Split the age string into value and unit\n",
    "    value, unit = age_str.split()\n",
    "    value = int(value)\n",
    "    \n",
    "    if 'year' in unit or 'years' in unit:\n",
    "        return value * 12\n",
    "    elif 'month' in unit or 'months' in unit:\n",
    "        return value\n",
    "    elif 'week' in unit or 'weeks' in unit:\n",
    "        return value // 4  # Approximate conversion: 1 month = 4 weeks\n",
    "    elif 'day' in unit or 'days' in unit:\n",
    "        return value // 30 # Approximate conversion: 1 month = 30 days\n",
    "    else:\n",
    "        return 0  # default case\n",
    "\n",
    "age_data = dog_data['Age upon Outcome']\n",
    "df = pd.DataFrame(age_data)\n",
    "df['Age upon Outcome'] = df['Age upon Outcome'].fillna('0 days')  #  fills NaN with '0 days'\n",
    "# Apply the conversion function to the column\n",
    "df['Age upon Outcome'] = df['Age upon Outcome'].apply(convert_to_months)\n",
    "# print(df.head())\n",
    "\n",
    "mean_age = df['Age upon Outcome'].mean()\n",
    "median_age = df['Age upon Outcome'].median()\n",
    "mode_age = df['Age upon Outcome'].mode()\n",
    "age_df = df\n",
    "\n",
    "print(f\"Mean Age (in months): {mean_age:.2f}\")\n",
    "print(f\"Median Age (in months): {median_age:.2f}\")\n",
    "print(f\"Mode Age (in months): {mode_age.iloc[0]}\")  \n",
    "\n",
    "age_counts = df.loc[(df['Age upon Outcome'] >= 0) & (df['Age upon Outcome'] <= 228), 'Age upon Outcome'].value_counts().sort_index()\n",
    "age_counts.plot(kind='bar', figsize=(12,6))\n",
    "plt.title('Distribution of Ages in Months')\n",
    "plt.xlabel('Age (in months)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ead8be",
   "metadata": {},
   "source": [
    "### Feature Engineering for Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677282b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the columns we don't need for our models\n",
    "dog_data.drop(columns=['Animal Type', 'MonthYear', 'Breed'], inplace=True)\n",
    "dog_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd90af21",
   "metadata": {},
   "source": [
    "#### Age: Years to Months\n",
    "Change age to be uniformly described by months. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e0e6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_data = dog_data.drop(columns=['Age upon Outcome'])\n",
    "dog_data = pd.concat([dog_data, df.iloc[:, 0]], axis=1)\n",
    "dog_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7115ff62",
   "metadata": {},
   "source": [
    "#### Encode Sex: \n",
    "This code performs one-hot encoding on the categorical columns 'Sex upon Outcome' and 'Color' in the 'dog_data' DataFrame, creating binary columns for each category. The encoded columns are then concatenated with the original DataFrame, and the original categorical columns are dropped, resulting in a DataFrame with expanded feature representations for 'Sex upon Outcome' and 'Color'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd13f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_sex = pd.get_dummies(dog_data['Sex upon Outcome'], prefix='Sex upon Outcome').astype(int)\n",
    "encoded_colors = pd.get_dummies(dog_data['Color'], prefix='Color').astype(int)\n",
    "dog_data = pd.concat([dog_data, encoded_sex, encoded_colors], axis=1)\n",
    "dog_data = dog_data.drop(columns=['Color', 'Sex upon Outcome'])\n",
    "dog_data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f61f0c",
   "metadata": {},
   "source": [
    "#### Encode Size: \n",
    "This code snippet encodes the 'Size' column in the 'dog_data' DataFrame ordinally based on predefined size categories. It creates a new column named 'Breed size' where each dog's size is represented by an ordinal encoding, and subsequently, the original 'Size' column is dropped from the DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1993db70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode breeds ordinally\n",
    "sizes = ['Small Breeds', 'Medium/Small Breeds', 'Medium/Large Breeds', 'Large Breeds']\n",
    "\n",
    "size_encode_mapping = {\n",
    "    'Small Breeds': 1,\n",
    "    'Medium/Small Breeds': 2,\n",
    "    'Medium Breeds': 3,\n",
    "    'Medium/Large Breeds': 4,\n",
    "    'Large Breeds': 5\n",
    "}\n",
    "\n",
    "dog_data['Breed size'] = dog_data['Size'].map(size_encode_mapping)\n",
    "dog_data = dog_data.drop(columns=['Size'])\n",
    "\n",
    "\n",
    "dog_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be8ee14",
   "metadata": {},
   "source": [
    "#### Encode Season: \n",
    "This code snippet encodes the 'Season' column in the 'dog_data' DataFrame cyclically using sine and cosine functions. It creates two new columns, 'Season_cos' and 'Season_sin', which represent the cyclic encoding of seasons. The original 'Season' column and an intermediate numeric encoding column are then dropped from the DataFrame, resulting in a dataset where seasons are represented as cyclical features through trigonometric functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c3c3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "## encode seasons cyclically with sine and cosine functions\n",
    "season_mapping = {'Winter': 0, 'Spring': 1, 'Summer': 2, 'Fall': 3}\n",
    "dog_data['Season_numeric_encode'] = dog_data['Season'].map(season_mapping)\n",
    "dog_data['Season_cos'] = np.cos(2 * np.pi * dog_data['Season_numeric_encode'] / 4)\n",
    "dog_data['Season_sin'] = np.sin(2 * np.pi * dog_data['Season_numeric_encode'] / 4)\n",
    "dog_data = dog_data.drop(columns=['Season', 'Season_numeric_encode'])\n",
    "dog_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765254a2",
   "metadata": {},
   "source": [
    "### Data Modeling\n",
    "We decided to only use dogs for this dataset because having cat and other would complicate results and cause\n",
    "our data to fall victim to the curse of dimensionality. Additionally, breed will likely play a large role in accuracy. In order to use breed, we will have to center our focus on dogs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3998776d",
   "metadata": {},
   "source": [
    "### Model 1. Naive Bayes\n",
    "First, we are using Naive Bayes on our data. The data has already been cleaned and engineered, so all we have to do is set the label and features variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb5f32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#only use these columns from the dataset\n",
    "# col_names = ['Sex upon Outcome', 'Breed', 'Color', 'Season']\n",
    "# NB_df = dog_data.loc[:, col_names]\n",
    "#append age from df and then append outcome type last\n",
    "# NB_df = pd.concat([NB_df, df.iloc[:, 0]], axis=1)\n",
    "# NB_df = pd.concat([NB_df, dog_data[['Outcome Type']]], axis=1)\n",
    "\n",
    "#set label col to Outcome Type\n",
    "label = dog_data['Outcome Type']\n",
    "label = label.values.ravel()\n",
    "features= dog_data.drop(['Outcome Type'],axis=1)\n",
    "\n",
    "\n",
    "#verify we have correct columns\n",
    "# NB_df.head()\n",
    "dog_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4707d42c",
   "metadata": {},
   "source": [
    " Next, create a Multinomial Naive Bayes classifier (since it supports categorical target \n",
    "variables) and perform a 10-fold cross validation on the classifier. \n",
    "Print accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395c510a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# verify shape is correct for NB model\n",
    "print(dog_data.shape)\n",
    "print(label.shape)\n",
    "\n",
    "# normalize and scale features\n",
    "features = pd.DataFrame(features)\n",
    "label = pd.DataFrame(label)\n",
    "le = LabelEncoder()\n",
    "features = features.apply(le.fit_transform)\n",
    "label = label.apply(le.fit_transform)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "features = scaler.fit_transform(features)\n",
    "\n",
    "# finally model data and check accuracy\n",
    "mnb = MultinomialNB()\n",
    "mnb_CV = cross_val_score(mnb, features, label, cv=10)\n",
    "print('Accuracy: ', mnb_CV.mean())\n",
    "\n",
    "warnings.resetwarnings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d5f543",
   "metadata": {},
   "source": [
    "### Model 2.5 Ensembling: (can move this later)\n",
    "Let's try ensembling with random forests. Ensembling base classifiers usually performs better because it combines the predictions of multiple base classifiers.\n",
    "\n",
    "#### Random forests: \n",
    "Let's use a GridSearchCV with a 3-fold CV and try 15, 25, and 50 base classifiers of fully grown decision trees and see which performs best. Then wrap the GridSearchCV in a cross_val_predict with 5-fold CV and display the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56be5281",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_predict\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "label = label.values.ravel()\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "parameter = {\n",
    "    'n_estimators': [15, 25, 50]\n",
    "}\n",
    "grid = GridSearchCV(rf, parameter, cv=3)\n",
    "pred = cross_val_predict(grid, features, label, cv=5)\n",
    "# CV_score = cross_val_score(grid, features, label, cv=5)\n",
    "# print('Accuracy: ', CV_score.mean())\n",
    "print('Classification Report: \\n', classification_report(label, pred))\n",
    "warnings.resetwarnings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69332cb0",
   "metadata": {},
   "source": [
    "#### Boosting: \n",
    "Let's use a GridSearchCV with a 3-fold CV and try 15, 25, and 50 base classifiers of decision stumps. Then wrap the GridSearchCV in a cross_val_predict with 5-fold CV and display the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60eeac8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "boost = AdaBoostClassifier()\n",
    "parameter = {\n",
    "    'n_estimators': [15, 25, 50]\n",
    "}\n",
    "grid = GridSearchCV(boost, parameter, cv=3)\n",
    "pred = cross_val_predict(grid, features, label, cv=5)\n",
    "print('Classification Report: \\n', classification_report(label, pred))\n",
    "warnings.resetwarnings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b30ae9",
   "metadata": {},
   "source": [
    "### Model 2. Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e19dbb2",
   "metadata": {},
   "source": [
    "Next, we will create a Decision Tree. I implemented hyperparameter optimization for a Decision Tree classifier using a grid search strategy to find the identify the most effective combination of hyperparametersâ€”specifically, the maximum depth of the Decision Tree (`max_depth`) and the number of splits in the StratifiedKFold cross-validator (`n_splits`). Further, a cross-validation was implemented to ensure the best split of the dataset.\n",
    "\n",
    "The script tracks the best hyperparameter values by comparing mean accuracies. The split that yields the best accuracy has max_depth of 10 and N-splits of 40. The best overall accuracy is 0.62."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc8000a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "X = dog_data.drop('Outcome Type', axis=1)\n",
    "y = dog_data['Outcome Type']\n",
    "\n",
    "# max_depth and n_splits we want to try\n",
    "max_depth_values = [5, 10, 15, 20]\n",
    "n_splits_values = [10, 20, 30, 40]\n",
    "\n",
    "best_mean_accuracy = 0\n",
    "best_max_depth = None\n",
    "best_n_splits = None\n",
    "\n",
    "# iterate over max_depth and n_splits values\n",
    "for max_depth in max_depth_values:\n",
    "    for n_splits in n_splits_values:\n",
    "        dt_model = DecisionTreeClassifier(random_state=42, max_depth=max_depth, min_samples_split=2)\n",
    "        cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "        # perform cross-validation\n",
    "        cv_scores = cross_val_score(dt_model, X, y, cv=cv, scoring='accuracy')\n",
    "        mean_accuracy = np.mean(cv_scores)\n",
    "\n",
    "        # update the best parameters if the current combination is better\n",
    "        if mean_accuracy > best_mean_accuracy:\n",
    "            best_mean_accuracy = mean_accuracy\n",
    "            best_max_depth = max_depth\n",
    "            best_n_splits = n_splits\n",
    "\n",
    "# print the best hyperparameters and mean accuracy\n",
    "print(\"Best Max Depth:\", best_max_depth)\n",
    "print(\"Best N_splits:\", best_n_splits)\n",
    "print(\"Best Mean Accuracy:\", best_mean_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c486aa",
   "metadata": {},
   "source": [
    "### Model 3: K-Nearest Neighbor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706fcbe2",
   "metadata": {},
   "source": [
    "The K-nearest neighbor modeling is an algorithm that's simple to understand and implement. It's simplicity and high accuracy potential is why we decided to use it to model our dataset. However, there are various additional considerations we must take into account when using KNN. In cases where a class inbalance exists, KNN is prone to break down. In our case, we have certain class labels that dominate our data. For example, the majority of our outcome instances are adoption, return to owner, and transfer. These outcomes are only three out of nine potential outcomes but make up about 95% of the outcome types in our data. We need to institute a measure to combat against this imbalance. Using weighted voting for our model will prevent the class imbalance from harming our results. In our grid search, weighted and uniform vote will be one of our parameters to see which hyperparameter leads to the better results. This will check for class imbalances worsening our model accuracy. We will also hypertune our parameter K to find a K value that fits our data well and can generalize to new data points too, avoiding overfitting or underfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f3b052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dog_data.head())\n",
    "# print(age_df.head())\n",
    "\n",
    "# get the column labels of the columns that will be used in our modeling\n",
    "col_names = ['Season', 'Color', 'Breed', 'Sex upon Outcome', 'Age in Months', 'Outcome Type']\n",
    "dog_data['Age in Months'] = age_df['Age upon Outcome']\n",
    "\n",
    "# add the data in the columns to the KNN_df\n",
    "KNN_df = dog_data.loc[:, col_names]\n",
    "# print(KNN_df.head())\n",
    "\n",
    "# tracking class frequencies\n",
    "value_counts = KNN_df['Outcome Type'].value_counts()\n",
    "print(value_counts)\n",
    "value_counts = KNN_df['Breed'].value_counts()\n",
    "print(value_counts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769f6545",
   "metadata": {},
   "source": [
    "Since breed size is an ordinal feature where sizes can be compared to each other (bigger sizes are larger than smaller sizes). We can encode this feature using numeric values to represent the size comparison between the feature categories. Larger sizes are represented with a higher number while smaller sizes are represented with a smaller number. \n",
    "\n",
    "For a feature like seasons that is considered cyclical (ex: winter is close to spring and also fall), we need a special way to deal with it. Sine and cosine functions is a common approach to implement circular encoding. Mapping data onto a unit circle will help represent the circular nature of our season feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1915a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode categorical data\n",
    "import sklearn\n",
    "import warnings\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# encode breeds ordinally\n",
    "sizes = ['Small Breeds', 'Medium/Small Breeds', 'Medium/Large Breeds', 'Large Breeds']\n",
    "\n",
    "size_encode_mapping = {\n",
    "    'Small Breeds': 1,\n",
    "    'Medium/Small Breeds': 2,\n",
    "    'Medium Breeds': 3,\n",
    "    'Medium/Large Breeds': 4,\n",
    "    'Large Breeds': 5\n",
    "}\n",
    "\n",
    "KNN_df['Breed encoded'] = KNN_df['Breed'].map(size_encode_mapping)\n",
    "\n",
    "## encode seasons cyclically with sine and cosine functions\n",
    "season_mapping = {'Winter': 0, 'Spring': 1, 'Summer': 2, 'Fall': 3}\n",
    "KNN_df['Season_numeric_encode'] = KNN_df['Season'].map(season_mapping)\n",
    "KNN_df['Season_cos'] = np.cos(2 * np.pi * KNN_df['Season_numeric_encode'] / 4)\n",
    "KNN_df['Season_sin'] = np.sin(2 * np.pi * KNN_df['Season_numeric_encode'] / 4)\n",
    "\n",
    "# # drop stolen records bc too few to make 5 fold \n",
    "# KNN_df = KNN_df[KNN_df['Outcome Type'] != 'Stolen']\n",
    "\n",
    "# encode sex and colors with one hot encode to 0/1 so features can all be scaled\n",
    "encoded_sex = pd.get_dummies(KNN_df['Sex upon Outcome'], prefix='Sex upon Outcome').astype(int)\n",
    "encoded_colors = pd.get_dummies(KNN_df['Color'], prefix='Color').astype(int)\n",
    "# encoded_seasons = pd.get_dummies(KNN_df['Season'], prefix='Season').astype(int)\n",
    "\n",
    "# combine encoded data into one data frame\n",
    "col_names_encoded = ['Breed encoded', 'Age in Months', 'Season_cos', 'Season_sin']\n",
    "KNN_df_encoded = KNN_df.loc[:, col_names_encoded]\n",
    "KNN_df_encoded = pd.concat([KNN_df_encoded, encoded_sex, encoded_colors, KNN_df['Outcome Type']], axis=1)\n",
    "KNN_df_encoded.dropna(inplace=True)\n",
    "print(KNN_df_encoded.head())\n",
    "\n",
    "warnings.resetwarnings()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8628efb",
   "metadata": {},
   "source": [
    "Training KNN Model -> we want to scale data before training model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d931d5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# seperate features & labels\n",
    "features = KNN_df_encoded.drop('Outcome Type', axis=1)\n",
    "labels = KNN_df_encoded['Outcome Type']\n",
    "\n",
    "# KNN with 80-20 train/test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "x_test = np.ascontiguousarray(x_test)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "x_test_scaled = np.ascontiguousarray(x_test_scaled)\n",
    "\n",
    "\n",
    "#initialize parameter grid to find best parameters\n",
    "param_grid = {\n",
    "    'n_neighbors': range(3, 25),\n",
    "    'weights': ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "#create knn classifier \n",
    "KNN_classifier = KNeighborsClassifier()\n",
    "\n",
    "# search for best parameters\n",
    "grid_search = GridSearchCV(KNN_classifier, param_grid, cv=4, scoring='accuracy')\n",
    "grid_search.fit(x_train_scaled, y_train)\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters for KNN model:\", best_params)\n",
    "\n",
    "warnings.resetwarnings()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b77e7e",
   "metadata": {},
   "source": [
    "Calculate the accuracy for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "24961d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Cross-Validated Accuracy: 0.6142133842089815\n",
      "Test Accuracy for each trial: 0.6124440531220192\n",
      "[0.55967493 0.55558409 0.57473584 0.56646243 0.58436674 0.57381861\n",
      " 0.59223657 0.58034928 0.5943462  0.58167009 0.60028984 0.5853757\n",
      " 0.60197755 0.58607279 0.60639859 0.58873276 0.60621515 0.5896133\n",
      " 0.6090769  0.59067728 0.60748092 0.59065894 0.60975565 0.59181465\n",
      " 0.60896683 0.59115424 0.61001247 0.59205313 0.6112966  0.59278691\n",
      " 0.61210376 0.59352069 0.61102143 0.59216319 0.61296595 0.59306208\n",
      " 0.6134796  0.594016   0.61355298 0.59423613 0.61421338 0.59397931\n",
      " 0.61340622 0.59452964]\n",
      "Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "       Adoption       0.65      0.90      0.76      6547\n",
      "           Died       1.00      0.00      0.00        55\n",
      "       Disposal       1.00      0.00      0.00        10\n",
      "     Euthanasia       1.00      0.00      0.00       340\n",
      "        Missing       1.00      0.00      0.00         4\n",
      "Return to Owner       0.48      0.35      0.40      3499\n",
      "      Rto-Adopt       1.00      0.00      0.00       129\n",
      "       Transfer       0.59      0.40      0.48      3045\n",
      "\n",
      "       accuracy                           0.61     13629\n",
      "      macro avg       0.84      0.21      0.20     13629\n",
      "   weighted avg       0.61      0.61      0.57     13629\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"Best Cross-Validated Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "# calculate accuracy using best parameters\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(x_test_scaled)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy for each trial:\", accuracy)\n",
    "avg_test_scores = grid_search.cv_results_['mean_test_score']\n",
    "print(avg_test_scores)\n",
    "\n",
    "# get classfification report\n",
    "report = classification_report(y_test, y_pred, zero_division=1)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "\n",
    "# # print(KNN_df_encoded.head())\n",
    "\n",
    "# # KNN_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
