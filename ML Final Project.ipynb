{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0adb00d2",
   "metadata": {},
   "source": [
    "# ML Final Project\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0622e3",
   "metadata": {},
   "source": [
    "### Shruti Kotha, Mia Tey, Jeni Pham, and Shruti Patel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "867e31cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Counter\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "#add imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bae3246",
   "metadata": {},
   "source": [
    "## Final Project Objective: \n",
    "Goal: Help determine the outcome of new intakes at the Austin Animal Center. Specfically, we determined that we can use the features (age, breed, color, animal, sex upon outcome, outcome subtype,\n",
    "name) to predict outcome (Foster, Adoption, Transfer, Euthanize) of dogs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3b313e",
   "metadata": {},
   "source": [
    "### Part 1. Data Preperation and data cleaning for Modeling\n",
    "\n",
    "For this part of the assignment we read in our data and will perform various data prep techniques like data cleaning and feature engineering to prepare our data for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8bdfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('animaloutcomes.csv', skipinitialspace = True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4778e330",
   "metadata": {},
   "source": [
    "View the distribution of \"Outcome Type\". We want to ensure there is sufficient data for each \"Outcome Type\" and if there isn't we can drop columns as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87958c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_counts = data['Outcome Type'].value_counts()\n",
    "print(outcome_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5370c6",
   "metadata": {},
   "source": [
    "First, our label column will be \"Outcome Type\", since that is what we want to predict. \n",
    "If there are any records that lack an entry for \"Outcome Type\" we drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e153ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Length before droping Outcome Type: \", len(data['Outcome Type']))\n",
    "data = data.dropna(subset=['Outcome Type'])\n",
    "print(\"Length after drop Outcome Type: \", len(data['Outcome Type']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df7ca72",
   "metadata": {},
   "source": [
    "Second, we want to drop \"Outcome Subtype\". Since most rows have NaN in the \"Outcome Subtype\" column, it won't be an important column for us to use in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfcfc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['Outcome Subtype', 'Name', 'DateTime', 'Date of Birth', 'Animal ID'], inplace=True)\n",
    "# print the head to ensure only columns important to us are in the dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5753a19d",
   "metadata": {},
   "source": [
    "Next, we clean up the colors column. Since we plan on using the colors for our models later, we should simplify the categories, as there are way too many unique categories for testing (23).\n",
    "First, there are entries such as 'black/white' and 'white/black' let's combine these into one label.\n",
    "Second, there are a lot of unique combinations of two colors. For these records whose combination of color makes up <5% of all colors, add these into one column called 'Multicolor' and jointly categorize it with the 'Tricolor' attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc59ee4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_count_before = len(data['Color'].value_counts())\n",
    "print(\"Number of unique colors before: \", color_count_before)\n",
    "\n",
    "# Combine categories such as 'black/white' and 'white/black'\n",
    "def join_same_color(color):\n",
    "    color_components = color.split('/')\n",
    "    color_components.sort()\n",
    "    return '/'.join(color_components)\n",
    "data['Color'] = data['Color'].apply(join_same_color)\n",
    "\n",
    "\n",
    "# Create Multicolor category \n",
    "color_counts = data['Color'].value_counts()\n",
    "color_percent = color_counts / color_counts.sum() * 100\n",
    "less_than_5_percent = color_percent[color_percent < 1].index\n",
    "data['Color'] = data['Color'].apply(lambda x: 'Multicolor' if x in less_than_5_percent or x == 'Tricolor' else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d68166",
   "metadata": {},
   "source": [
    "Next, we decied to create new column for seasons. Given that each month's scope was too broad to determine animal outcomes accurately. We noticed season had more of an impact on animal outtake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a88081",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_season(month):\n",
    "    if month in [3, 4, 5]:\n",
    "        return 'Spring'\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 'Summer'\n",
    "    elif month in [9, 10, 11]:\n",
    "        return 'Fall'\n",
    "    else:\n",
    "        return 'Winter'\n",
    "    \n",
    "data['Month'] = pd.to_datetime(data['MonthYear'], format='%b %Y').dt.month\n",
    "data['Season'] = data['Month'].apply(get_season)\n",
    "data = data.drop('Month', axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed70a63b",
   "metadata": {},
   "source": [
    "Next, we decieded to categorize each breed into the size of the breed. We noticed our data had too many specific breeds, thus decided to genralize the data. We kept the data of the top most 100 frequent dog breeds and categorized them into their respective size. \n",
    "\n",
    "We'll be categorizing the various breeds in the dataset. https://www.trainpetdog.com/dog-breed-size-chart/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38200fd2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# only keep records that are Dogs\n",
    "records_to_keep = ['Dog']\n",
    "dog_data = data[data['Animal Type'].isin(records_to_keep)]\n",
    "\n",
    "# only keep top 100 most frequent dog breeds in dataset\n",
    "top_100_breeds = dog_data['Breed'].value_counts().head(100).index\n",
    "breeds_data = dog_data[dog_data['Breed'].isin(top_100_breeds)]\n",
    "breeds_data = breeds_data.copy()\n",
    "\n",
    "# print(top_100_breeds)\n",
    "\n",
    "\n",
    "\n",
    "# large 70 + lbs avg, small, medium\n",
    "breed_to_category = {\n",
    "    'Pit Bull Mix': 'Medium/Large Breeds',\n",
    "    'Labrador Retriever Mix': 'Medium/Large Breeds',\n",
    "    'Chihuahua Shorthair Mix': 'Small Breeds',\n",
    "    'German Shepherd Mix': 'Medium/Large Breeds',\n",
    "    'Pit Bull': 'Medium/Large Breeds',\n",
    "    'Australian Cattle Dog Mix': 'Medium/Large Breeds',\n",
    "    'Chihuahua Shorthair': 'Small Breeds',\n",
    "    'Labrador Retriever': 'Medium/Large Breeds',\n",
    "    'German Shepherd': 'Medium/Large Breeds',\n",
    "    'Dachshund Mix': 'Medium/Small Breeds', \n",
    "    'Boxer Mix': 'Medium/Large Breeds',\n",
    "    'Border Collie Mix': 'Medium/Large Breeds',\n",
    "    'Miniature Poodle Mix': 'Small Breeds',\n",
    "    'Siberian Husky Mix': 'Medium Breeds',\n",
    "    'Australian Shepherd Mix': 'Medium/Large Breeds',\n",
    "    'Catahoula Mix': 'Medium/Large Breeds',\n",
    "    'Staffordshire Mix': 'Medium/Large Breeds',\n",
    "    'Siberian Husky': 'Medium Breeds',\n",
    "    'Rat Terrier Mix': 'Small Breeds',\n",
    "    'Great Pyrenees Mix': 'Large Breeds',\n",
    "    'Yorkshire Terrier Mix': 'Small Breeds',\n",
    "    'Beagle Mix': 'Medium/Large Breeds',\n",
    "    'Miniature Schnauzer Mix': 'Medium/Small Breeds',\n",
    "    'Jack Russell Terrier Mix': 'Medium/Small Breeds',\n",
    "    'Pointer Mix': 'Large Breeds',\n",
    "    'Cairn Terrier Mix' : 'Small Breeds',\n",
    "    'American Bulldog Mix': 'Medium/Large Breeds',                      \n",
    "    'Chihuahua Longhair Mix': 'Small Breeds',   \n",
    "    'Anatol Shepherd Mix': 'Medium/Large Breeds',\n",
    "    'Rottweiler Mix': 'Medium/Large Breeds',\n",
    "    'Australian Cattle Dog': 'Medium Breeds',\n",
    "    'Black Mouth Cur Mix': 'Medium/Large Breeds',\n",
    "    'Plott Hound Mix': 'Medium/Large Breeds',\n",
    "    'Labrador Retriever/Pit Bull': 'Medium/Large Breeds',\n",
    "    'Australian Kelpie Mix': 'Medium Breeds',\n",
    "    'Shih Tzu Mix': 'Small Breeds',\n",
    "    'Chihuahua Shorthair/Dachshund': 'Small Breeds',\n",
    "    'Great Pyrenees': 'Large Breeds',\n",
    "    'American Pit Bull Terrier Mix': 'Medium/Large Breeds',\n",
    "    'German Shepherd/Labrador Retriever': 'Large Breeds',\n",
    "    'Dachshund/Chihuahua Shorthair': 'Small Breeds',\n",
    "    'Labrador Retriever/German Shepherd': 'Large Breeds',\n",
    "    'American Staffordshire Terrier Mix': 'Medium/Large Breeds',\n",
    "    'Rottweiler': 'Large Breeds',\n",
    "    'Boxer': 'Medium/Large Breeds',\n",
    "    'Shih Tzu': 'Small Breeds',\n",
    "    'Pit Bull/Labrador Retriever': 'Medium/Large Breeds',\n",
    "    'Dachshund': 'Small Breeds',\n",
    "    'Golden Retriever Mix': 'Large Breeds',\n",
    "    'Maltese Mix': 'Small Breeds',\n",
    "    'Border Terrier Mix': 'Small Breeds',\n",
    "    'Miniature Pinscher Mix': 'Small Breeds',\n",
    "    'Yorkshire Terrier': 'Small Breeds',\n",
    "    'Blue Lacy Mix': 'Medium/Large Breeds',\n",
    "    'Doberman Pinsch Mix': 'Medium/Large Breeds',\n",
    "    'Miniature Poodle': 'Small Breeds',\n",
    "    'Chow Chow Mix': 'Medium/Large Breeds',\n",
    "    'American Pit Bull Terrier': 'Medium/Large Breeds',\n",
    "    'Cairn Terrier': 'Small Breeds',\n",
    "    'Border Collie': 'Medium/Large Breeds',\n",
    "    'Queensland Heeler Mix': 'Medium Breeds',\n",
    "    'Doberman Pinsch': 'Medium/Large Breeds',\n",
    "    'Basset Hound Mix': 'Medium/Large Breeds',\n",
    "    'Labrador Retriever/Border Collie': 'Large Breeds',\n",
    "    'Alaskan Husky Mix': 'Medium/Large Breeds',\n",
    "    'Pug Mix': 'Small Breeds',\n",
    "    'Beagle': 'Small Breeds',\n",
    "    'Pomeranian Mix': 'Small Breeds',\n",
    "    'Mastiff Mix': 'Large Breeds',\n",
    "    'Cocker Spaniel Mix': 'Small Breeds',\n",
    "    'Cardigan Welsh Corgi Mix': 'Medium Breeds',\n",
    "    'Miniature Schnauzer': 'Small Breeds',\n",
    "    'Lhasa Apso Mix': 'Small Breeds',\n",
    "    'Chinese Sharpei Mix': 'Medium/Large Breeds',\n",
    "    'Australian Shepherd': 'Medium/Large Breeds',\n",
    "    'Labrador Retriever/Australian Cattle Dog': 'Medium/Large Breeds',\n",
    "    'Black/Tan Hound Mix': 'Medium/Large Breeds',\n",
    "    'Pug': 'Small Breeds',\n",
    "    'Chihuahua Longhair': 'Small Breeds',\n",
    "    'Great Dane Mix': 'Large Breeds',\n",
    "    'Boston Terrier Mix': 'Small Breeds',\n",
    "    'Border Collie/Labrador Retriever': 'Large Breeds',\n",
    "    'Labrador Retriever/Great Pyrenees' : 'Large Breeds',\n",
    "    'Dachshund Wirehair Mix' : 'Small Breeds',\n",
    "    'Dachshund Longhair Mix' : 'Small Breeds',\n",
    "    'Alaskan Husky' : 'Medium/Large Breeds',\n",
    "    'Flat Coat Retriever Mix' : 'Large Breeds',\n",
    "    'Manchester Terrier Mix' : 'Small Breeds',\n",
    "    'Toy Poodle Mix' : 'Small Breeds',\n",
    "    'American Bulldog' : 'Medium/Large Breeds',\n",
    "    'Rat Terrier' : 'Small Breeds',\n",
    "    'Collie Smooth Mix' : 'Medium/Large Breeds',\n",
    "    'Maltese' : 'Small Breeds',\n",
    "    'Anatol Shepherd' : 'Medium/Large Breeds',\n",
    "    'Staffordshire' : 'Medium/Large Breeds',\n",
    "    'Belgian Malinois Mix' : 'Medium/Large Breeds',\n",
    "    'Pit Bull/Boxer' : 'Medium/Large Breeds',\n",
    "    'Norfolk Terrier Mix' : 'Small Breeds',\n",
    "    'Australian Cattle Dog/Labrador Retriever' : 'Medium/Large Breeds',\n",
    "    'Rhod Ridgeback Mix' : 'Large Breeds'         \n",
    "}\n",
    "print()\n",
    "print(\"Distribution based on size of breed:\")\n",
    "\n",
    "categories = [breed_to_category.get(breed) for breed in breeds_data['Breed']]\n",
    "\n",
    "category_counts = Counter(categories)\n",
    "\n",
    "# make sure there is still sufficent data for each size of the animal\n",
    "for category, count in category_counts.items():\n",
    "    print(f'{category}: {count}')\n",
    "\n",
    "# to do add a size category with the breed to wsize mapping\n",
    "breeds_data.loc[:, 'Size'] = breeds_data['Breed'].map(breed_to_category)\n",
    "dog_data = breeds_data\n",
    "\n",
    "\n",
    "# make sure there is a new Size column that reflects the size of the breed for that animal\n",
    "dog_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0394fb8f",
   "metadata": {},
   "source": [
    "### Part 2. Data Exploration "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77a17ee",
   "metadata": {},
   "source": [
    "We will be graphing data distributions as part of data exploration. We will be looking for any imbalances, outliers, or anything that could potentially skeww the results of our data. We will then correct that before modeling.\n",
    "\n",
    "Plot distribution of colors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661ef458",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_counts = dog_data['Color'].value_counts()\n",
    "color_counts.plot(kind='pie', autopct='%1.1f%%')\n",
    "plt.title('Distribution of Colors')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ceb18d3",
   "metadata": {},
   "source": [
    "Display of distribution of season and outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb3fee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "season_counts = dog_data['Season'].value_counts()\n",
    "season_counts.plot(kind='bar')\n",
    "plt.title('Frequency of Seasons within dataset')\n",
    "plt.xlabel('Season')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=0)  \n",
    "plt.show()\n",
    "\n",
    "outcome_by_season = pd.crosstab(dog_data['Season'], dog_data['Outcome Type'])\n",
    "outcome_by_season.plot(kind='bar', stacked=True)\n",
    "plt.title('Outcomes by Season')\n",
    "plt.xlabel('Season')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=0)  \n",
    "plt.legend(loc='upper right', bbox_to_anchor=(1.5, 1))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bee290f",
   "metadata": {},
   "source": [
    "Distribution of dog breed sizes for the top 100 breeds in the dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e4789c",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_labels = [label for label, value in category_counts.items() if label is not None]\n",
    "category_values = [value for label, value in category_counts.items() if label is not None]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(category_labels, category_values)\n",
    "plt.title('Distribution of Dog Breeds by Category')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7e0827",
   "metadata": {},
   "source": [
    "Distribution of dog sex upon Outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8139a0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_upon_outcome = dog_data[\"Sex upon Outcome\"]\n",
    "\n",
    "male = 0\n",
    "female = 0\n",
    "\n",
    "for outcome in sex_upon_outcome:\n",
    "    if pd.notna(outcome):\n",
    "        if \"Male\" in outcome:\n",
    "            male += 1\n",
    "        elif \"Female\" in outcome:\n",
    "            female += 1\n",
    "\n",
    "        \n",
    "categories = [\"Male\", \"Female\"]\n",
    "counts = [male, female]\n",
    "\n",
    "plt.bar(categories, counts)\n",
    "plt.title(\"Distribution of Male and Female\")\n",
    "plt.xlabel(\"Sex\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Number of Males: {male}\")\n",
    "print(f\"Number of Females: {female}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ceaef69",
   "metadata": {},
   "source": [
    "Distrubtion of nuetured vs spayed at outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999da4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "neutered = 0\n",
    "spayed = 0\n",
    "intact = 0\n",
    "\n",
    "sex_counts = dog_data[\"Sex upon Outcome\"].value_counts()\n",
    "print(sex_counts)\n",
    "\n",
    "for outcome in sex_upon_outcome:\n",
    "    if pd.notna(outcome):\n",
    "        if \"Neutered\" in outcome:\n",
    "            neutered += 1\n",
    "        elif \"Spayed\" in outcome:\n",
    "            spayed += 1\n",
    "        elif \"Intact\" in outcome: \n",
    "            intact += 1\n",
    "        \n",
    "categories = [\"Neutered\", \"Spayed\", \"Intact\"]\n",
    "counts = [neutered, spayed, intact]\n",
    "\n",
    "plt.bar(categories, counts)\n",
    "plt.title(\"Distribution of Neutered, Spayed, or Intact\")\n",
    "plt.xlabel(\"Sterilization Status\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Number of Neutered: {neutered}\")\n",
    "print(f\"Number of Spayed: {spayed}\")\n",
    "print(f\"Number of Intact: {intact}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d442544",
   "metadata": {},
   "source": [
    "Distribution of Months when animals were registered (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63657884",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_data = dog_data['MonthYear']\n",
    "df = pd.DataFrame(month_data)\n",
    "pattern = r'([a-zA-Z]{3}) \\d{4}'\n",
    "df['MonthYear'] = df['MonthYear'].str.extract(pattern)\n",
    "# print(df)\n",
    "data.head()\n",
    "month_order = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "month_counts = df['MonthYear'].value_counts()\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=month_counts.index, y=month_counts.values, order=month_order)\n",
    "plt.title('Distribution of Months')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2c206a",
   "metadata": {},
   "source": [
    "Convert the age upon outcome into months so all ages are generalized and then plot the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc53045",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_months(age_str):\n",
    "    # Split the age string into value and unit\n",
    "    value, unit = age_str.split()\n",
    "    value = int(value)\n",
    "    \n",
    "    if 'year' in unit or 'years' in unit:\n",
    "        return value * 12\n",
    "    elif 'month' in unit or 'months' in unit:\n",
    "        return value\n",
    "    elif 'week' in unit or 'weeks' in unit:\n",
    "        return value // 4  # Approximate conversion: 1 month = 4 weeks\n",
    "    elif 'day' in unit or 'days' in unit:\n",
    "        return value // 30 # Approximate conversion: 1 month = 30 days\n",
    "    else:\n",
    "        return 0  # default case\n",
    "\n",
    "age_data = dog_data['Age upon Outcome']\n",
    "df = pd.DataFrame(age_data)\n",
    "df['Age upon Outcome'] = df['Age upon Outcome'].fillna('0 days')  #  fills NaN with '0 days'\n",
    "# Apply the conversion function to the column\n",
    "df['Age upon Outcome'] = df['Age upon Outcome'].apply(convert_to_months)\n",
    "# print(df.head())\n",
    "\n",
    "mean_age = df['Age upon Outcome'].mean()\n",
    "median_age = df['Age upon Outcome'].median()\n",
    "mode_age = df['Age upon Outcome'].mode()\n",
    "age_df = df\n",
    "\n",
    "print(f\"Mean Age (in months): {mean_age:.2f}\")\n",
    "print(f\"Median Age (in months): {median_age:.2f}\")\n",
    "print(f\"Mode Age (in months): {mode_age.iloc[0]}\")  \n",
    "\n",
    "age_counts = df.loc[(df['Age upon Outcome'] >= 0) & (df['Age upon Outcome'] <= 228), 'Age upon Outcome'].value_counts().sort_index()\n",
    "age_counts.plot(kind='bar', figsize=(12,6))\n",
    "plt.title('Distribution of Ages in Months')\n",
    "plt.xlabel('Age (in months)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42efd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove any negative ages\n",
    "df = df[df['Age upon Outcome'] >= 0]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=df['Age upon Outcome'])\n",
    "plt.xlabel('Age upon Outcome')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title(f'Box-and-Whisker Plot')\n",
    "plt.show()\n",
    "q1 = df['Age upon Outcome'].quantile(0.25)\n",
    "q3 = df['Age upon Outcome'].quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "print(f\"50% of dog's ages in the dataset are between: {q1} and {q3} months\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ead8be",
   "metadata": {},
   "source": [
    "### Part 3. Feature Engineering for Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677282b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the columns we don't need for our models\n",
    "dog_data.drop(columns=['Animal Type', 'MonthYear', 'Breed'], inplace=True)\n",
    "dog_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd90af21",
   "metadata": {},
   "source": [
    "#### Age: Years to Months\n",
    "Change age to be uniformly described by months. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e0e6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_data = dog_data.drop(columns=['Age upon Outcome'])\n",
    "dog_data = pd.concat([dog_data, df.iloc[:, 0]], axis=1)\n",
    "dog_data = dog_data[dog_data['Age upon Outcome'] >= 0]\n",
    "dog_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7115ff62",
   "metadata": {},
   "source": [
    "#### Encode Sex: \n",
    "This code performs one-hot encoding on the categorical columns 'Sex upon Outcome' and 'Color' in the 'dog_data' DataFrame, creating binary columns for each category. The encoded columns are then concatenated with the original DataFrame, and the original categorical columns are dropped, resulting in a DataFrame with expanded feature representations for 'Sex upon Outcome' and 'Color'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd13f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_sex = pd.get_dummies(dog_data['Sex upon Outcome'], prefix='Sex upon Outcome').astype(int)\n",
    "encoded_colors = pd.get_dummies(dog_data['Color'], prefix='Color').astype(int)\n",
    "dog_data = pd.concat([dog_data, encoded_sex, encoded_colors], axis=1)\n",
    "dog_data = dog_data.drop(columns=['Color', 'Sex upon Outcome'])\n",
    "dog_data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f61f0c",
   "metadata": {},
   "source": [
    "#### Encode Size: \n",
    "This code snippet encodes the 'Size' column in the 'dog_data' DataFrame ordinally based on predefined size categories. It creates a new column named 'Breed size' where each dog's size is represented by an ordinal encoding, and subsequently, the original 'Size' column is dropped from the DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1993db70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode breeds ordinally\n",
    "sizes = ['Small Breeds', 'Medium/Small Breeds', 'Medium/Large Breeds', 'Large Breeds']\n",
    "\n",
    "size_encode_mapping = {\n",
    "    'Small Breeds': 1,\n",
    "    'Medium/Small Breeds': 2,\n",
    "    'Medium Breeds': 3,\n",
    "    'Medium/Large Breeds': 4,\n",
    "    'Large Breeds': 5\n",
    "}\n",
    "\n",
    "dog_data['Breed size'] = dog_data['Size'].map(size_encode_mapping)\n",
    "dog_data = dog_data.drop(columns=['Size'])\n",
    "\n",
    "\n",
    "dog_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be8ee14",
   "metadata": {},
   "source": [
    "#### Encode Season: \n",
    "This code snippet encodes the 'Season' column in the 'dog_data' DataFrame cyclically using sine and cosine functions. It creates two new columns, 'Season_cos' and 'Season_sin', which represent the cyclic encoding of seasons. The original 'Season' column and an intermediate numeric encoding column are then dropped from the DataFrame, resulting in a dataset where seasons are represented as cyclical features through trigonometric functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c3c3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "## encode seasons cyclically with sine and cosine functions\n",
    "season_mapping = {'Winter': 0, 'Spring': 1, 'Summer': 2, 'Fall': 3}\n",
    "dog_data['Season_numeric_encode'] = dog_data['Season'].map(season_mapping)\n",
    "dog_data['Season_cos'] = np.cos(2 * np.pi * dog_data['Season_numeric_encode'] / 4)\n",
    "dog_data['Season_sin'] = np.sin(2 * np.pi * dog_data['Season_numeric_encode'] / 4)\n",
    "dog_data = dog_data.drop(columns=['Season', 'Season_numeric_encode'])\n",
    "dog_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765254a2",
   "metadata": {},
   "source": [
    "### Part 4. Data Modeling\n",
    "We decided to only use dogs for this dataset because having cat and other would complicate results and cause\n",
    "our data to fall victim to the curse of dimensionality. Additionally, breed will likely play a large role in accuracy. In order to use breed, we will have to center our focus on dogs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3998776d",
   "metadata": {},
   "source": [
    "### Model 1. Naive Bayes\n",
    "First, we are using Naive Bayes on our data. The data has already been cleaned and engineered, so all we have to do is set the label and features variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb5f32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#only use these columns from the dataset\n",
    "# col_names = ['Sex upon Outcome', 'Breed', 'Color', 'Season']\n",
    "# NB_df = dog_data.loc[:, col_names]\n",
    "#append age from df and then append outcome type last\n",
    "# NB_df = pd.concat([NB_df, df.iloc[:, 0]], axis=1)\n",
    "# NB_df = pd.concat([NB_df, dog_data[['Outcome Type']]], axis=1)\n",
    "\n",
    "#set label col to Outcome Type\n",
    "label = dog_data['Outcome Type']\n",
    "label = label.values.ravel()\n",
    "features= dog_data.drop(['Outcome Type'],axis=1)\n",
    "\n",
    "\n",
    "#verify we have correct columns\n",
    "# NB_df.head()\n",
    "dog_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4707d42c",
   "metadata": {},
   "source": [
    " Next, create a Multinomial Naive Bayes classifier (since it supports categorical target \n",
    "variables) and perform a 10-fold cross validation on the classifier. \n",
    "Print accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395c510a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# verify shape is correct for NB model\n",
    "print(dog_data.shape)\n",
    "print(label.shape)\n",
    "\n",
    "# normalize and scale features\n",
    "features = pd.DataFrame(features)\n",
    "label = pd.DataFrame(label)\n",
    "le = LabelEncoder()\n",
    "features = features.apply(le.fit_transform)\n",
    "label = label.apply(le.fit_transform)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "features = scaler.fit_transform(features)\n",
    "\n",
    "# finally model data and check accuracy\n",
    "mnb = MultinomialNB()\n",
    "mnb_CV = cross_val_score(mnb, features, label, cv=10)\n",
    "print('Accuracy: ', mnb_CV.mean())\n",
    "\n",
    "warnings.resetwarnings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164413e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "class_names = np.unique(dog_data['Outcome Type'])\n",
    "cm = confusion_matrix(label, pred)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Confusion Matrix for Naive Bayes')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d5f543",
   "metadata": {},
   "source": [
    "### Model 2.5 Ensembling: (can move this later)\n",
    "Let's try ensembling with random forests. Ensembling base classifiers usually performs better because it combines the predictions of multiple base classifiers.\n",
    "\n",
    "#### Random forests: \n",
    "Let's use a GridSearchCV with a 3-fold CV and try 15, 25, and 50 base classifiers of fully grown decision trees and see which performs best. Then wrap the GridSearchCV in a cross_val_predict with 5-fold CV and display the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56be5281",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_predict\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "label = label.values.ravel()\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "parameter = {\n",
    "    'n_estimators': [15, 25, 50]\n",
    "}\n",
    "grid = GridSearchCV(rf, parameter, cv=3)\n",
    "pred = cross_val_predict(grid, features, label, cv=5)\n",
    "# CV_score = cross_val_score(grid, features, label, cv=5)\n",
    "# print('Accuracy: ', CV_score.mean())\n",
    "print('Classification Report: \\n', classification_report(label, pred))\n",
    "warnings.resetwarnings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ceb18c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "class_names = np.unique(dog_data['Outcome Type'])\n",
    "cm = confusion_matrix(label, pred)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Confusion Matrix for Random Forest')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69332cb0",
   "metadata": {},
   "source": [
    "#### Boosting: \n",
    "Let's use a GridSearchCV with a 3-fold CV and try 15, 25, and 50 base classifiers of decision stumps. Then wrap the GridSearchCV in a cross_val_predict with 5-fold CV and display the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "60eeac8f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GridSearchCV' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m boost \u001b[38;5;241m=\u001b[39m AdaBoostClassifier()\n\u001b[1;32m      5\u001b[0m parameter \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m25\u001b[39m, \u001b[38;5;241m50\u001b[39m]\n\u001b[1;32m      7\u001b[0m }\n\u001b[0;32m----> 8\u001b[0m grid \u001b[38;5;241m=\u001b[39m \u001b[43mGridSearchCV\u001b[49m(boost, parameter, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m      9\u001b[0m pred \u001b[38;5;241m=\u001b[39m cross_val_predict(grid, features, label, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClassification Report: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m, classification_report(label, pred))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'GridSearchCV' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "boost = AdaBoostClassifier()\n",
    "parameter = {\n",
    "    'n_estimators': [15, 25, 50]\n",
    "}\n",
    "grid = GridSearchCV(boost, parameter, cv=3)\n",
    "pred = cross_val_predict(grid, features, label, cv=5)\n",
    "print('Classification Report: \\n', classification_report(label, pred))\n",
    "warnings.resetwarnings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3e76872b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix\n\u001b[1;32m      3\u001b[0m class_names \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(dog_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOutcome Type\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 4\u001b[0m cm \u001b[38;5;241m=\u001b[39m confusion_matrix(label, \u001b[43mpred\u001b[49m)\n\u001b[1;32m      5\u001b[0m sns\u001b[38;5;241m.\u001b[39mheatmap(cm, annot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m\"\u001b[39m, xticklabels\u001b[38;5;241m=\u001b[39mclass_names, yticklabels\u001b[38;5;241m=\u001b[39mclass_names)\n\u001b[1;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConfusion Matrix for Boosting\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pred' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "class_names = np.unique(dog_data['Outcome Type'])\n",
    "cm = confusion_matrix(label, pred)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Confusion Matrix for Boosting')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b30ae9",
   "metadata": {},
   "source": [
    "### Model 2. Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e19dbb2",
   "metadata": {},
   "source": [
    "Next, we will create a Decision Tree. I implemented hyperparameter optimization for a Decision Tree classifier using a grid search strategy to find the identify the most effective combination of hyperparametersâ€”specifically, the maximum depth of the Decision Tree (`max_depth`) and the number of splits in the StratifiedKFold cross-validator (`n_splits`). Further, a cross-validation was implemented to ensure the best split of the dataset.\n",
    "\n",
    "The script tracks the best hyperparameter values by comparing mean accuracies. The split that yields the best accuracy has max_depth of 10 and N-splits of 40. The best overall accuracy is 0.62."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2bc8000a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Max Depth: 10\n",
      "Best N_splits: 40\n",
      "Best Mean Accuracy: 0.6211581708887106\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "X = dog_data.drop('Outcome Type', axis=1)\n",
    "y = dog_data['Outcome Type']\n",
    "\n",
    "# max_depth and n_splits we want to try\n",
    "max_depth_values = [5, 10, 15, 20]\n",
    "n_splits_values = [10, 20, 30, 40]\n",
    "\n",
    "best_mean_accuracy = 0\n",
    "best_max_depth = None\n",
    "best_n_splits = None\n",
    "\n",
    "# iterate over max_depth and n_splits values\n",
    "for max_depth in max_depth_values:\n",
    "    for n_splits in n_splits_values:\n",
    "        dt_model = DecisionTreeClassifier(random_state=42, max_depth=max_depth, min_samples_split=2)\n",
    "        cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "        # perform cross-validation\n",
    "        cv_scores = cross_val_score(dt_model, X, y, cv=cv, scoring='accuracy')\n",
    "        mean_accuracy = np.mean(cv_scores)\n",
    "\n",
    "        # update the best parameters if the current combination is better\n",
    "        if mean_accuracy > best_mean_accuracy:\n",
    "            best_mean_accuracy = mean_accuracy\n",
    "            best_max_depth = max_depth\n",
    "            best_n_splits = n_splits\n",
    "\n",
    "# print the best hyperparameters and mean accuracy\n",
    "print(\"Best Max Depth:\", best_max_depth)\n",
    "print(\"Best N_splits:\", best_n_splits)\n",
    "print(\"Best Mean Accuracy:\", best_mean_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e23b69e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Best hyperparameters\n",
    "best_max_depth = 10\n",
    "best_n_splits = 40\n",
    "\n",
    "# Split the data for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model with the best hyperparameters\n",
    "dt_model = DecisionTreeClassifier(random_state=42, max_depth=best_max_depth, min_samples_split=2)\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = dt_model.predict(X_test)\n",
    "\n",
    "# Create a confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Display the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c486aa",
   "metadata": {},
   "source": [
    "### Model 3: K-Nearest Neighbor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706fcbe2",
   "metadata": {},
   "source": [
    "The K-nearest neighbor modeling is an algorithm that's simple to understand and implement. It's simplicity and high accuracy potential is why we decided to use it to model our dataset. However, there are various additional considerations we must take into account when using KNN. In cases where a class inbalance exists, KNN is prone to break down. In our case, we have certain class labels that dominate our data. For example, the majority of our outcome instances are adoption, return to owner, and transfer. These outcomes are only three out of nine potential outcomes but make up about 95% of the outcome types in our data. We need to institute a measure to combat against this imbalance. Using weighted voting for our model will prevent the class imbalance from harming our results. In our grid search, weighted and uniform vote will be one of our parameters to see which hyperparameter leads to the better results. This will check for class imbalances worsening our model accuracy. We will also hypertune our parameter K to find a K value that fits our data well and can generalize to new data points too, avoiding overfitting or underfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8628efb",
   "metadata": {},
   "source": [
    "Here we're training KNN Model. Grid search will allow us to optimize for our paramaters. We also want to scale our data before training the model since the KNN's algorithm is based on distance and we want to make sure each feature's distances are on the same scale. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d931d5b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters for KNN model: {'n_neighbors': 23, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# seperate features & labels\n",
    "features = dog_data.drop('Outcome Type', axis=1)\n",
    "labels = dog_data['Outcome Type']\n",
    "\n",
    "# KNN with 80-20 train/test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "x_test = np.ascontiguousarray(x_test)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "x_test_scaled = np.ascontiguousarray(x_test_scaled)\n",
    "\n",
    "\n",
    "#initialize parameter grid to find best parameters\n",
    "param_grid = {\n",
    "    'n_neighbors': range(3, 25),\n",
    "    'weights': ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "#create knn classifier \n",
    "KNN_classifier = KNeighborsClassifier()\n",
    "\n",
    "# search for best parameters\n",
    "grid_search = GridSearchCV(KNN_classifier, param_grid, cv=4, scoring='accuracy')\n",
    "grid_search.fit(x_train_scaled, y_train)\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters for KNN model:\", best_params)\n",
    "\n",
    "warnings.resetwarnings()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b77e7e",
   "metadata": {},
   "source": [
    "Calculate the accuracy for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "24961d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Cross-Validated Accuracy: 0.6139198708541239\n",
      "Test Accuracy for each trial: 0.6115635776652726\n",
      "[0.55963824 0.55591429 0.57508439 0.56679263 0.58524729 0.57411212\n",
      " 0.59242002 0.58077121 0.59535515 0.58218374 0.60074846 0.58594438\n",
      " 0.60245451 0.58667816 0.60641694 0.58911799 0.60711403 0.59029205\n",
      " 0.60922366 0.59126431 0.60748092 0.59119093 0.6090769  0.59262181\n",
      " 0.60953552 0.59201644 0.61025095 0.59276856 0.61193866 0.59353904\n",
      " 0.61215879 0.59407103 0.61080129 0.59275022 0.61278251 0.59374083\n",
      " 0.61311271 0.59456633 0.61371808 0.59506164 0.61391987 0.59474978\n",
      " 0.61358967 0.59542853]\n",
      "Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "       Adoption       0.65      0.90      0.76      6547\n",
      "           Died       1.00      0.00      0.00        55\n",
      "       Disposal       1.00      0.00      0.00        10\n",
      "     Euthanasia       1.00      0.00      0.00       340\n",
      "        Missing       1.00      0.00      0.00         4\n",
      "Return to Owner       0.48      0.34      0.40      3499\n",
      "      Rto-Adopt       1.00      0.00      0.00       129\n",
      "       Transfer       0.59      0.40      0.48      3045\n",
      "\n",
      "       accuracy                           0.61     13629\n",
      "      macro avg       0.84      0.21      0.20     13629\n",
      "   weighted avg       0.61      0.61      0.57     13629\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"Best Cross-Validated Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "# calculate accuracy using best parameters\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(x_test_scaled)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy for each trial:\", accuracy)\n",
    "avg_test_scores = grid_search.cv_results_['mean_test_score']\n",
    "print(avg_test_scores)\n",
    "\n",
    "# get classfification report\n",
    "report = classification_report(y_test, y_pred, zero_division=1)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f5c680",
   "metadata": {},
   "source": [
    "SVM -> was taking wayy too long to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ec36c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC\n",
    "\n",
    "# features = dog_data.drop('Outcome Type', axis=1)\n",
    "# labels = dog_data['Outcome Type']\n",
    "\n",
    "# # test different c + kernel hyperparameters\n",
    "# param_grid = {\n",
    "#     'C': [0.1, 1, 10],\n",
    "#     'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "# }\n",
    "\n",
    "# x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# x_train = scaler.fit_transform(x_train)\n",
    "# x_test = scaler.transform(x_test)\n",
    "# svm_model = SVC()\n",
    "# grid_search = GridSearchCV(svm_model, param_grid, cv=4, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "# grid_search.fit(x_train, y_train)\n",
    "# print(\"Best Parameters:\", grid_search.best_params_)\n",
    "# y_pred = grid_search.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec140cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(\"accuracy of SVM model : \", accuracy)\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cd63c0",
   "metadata": {},
   "source": [
    "A potential reason for low accuracy could be the class imbalance that exists within the dataset. We have a lot of data/records for certain classes + those are the classes that tend to have to most data predicted accurately whereas underrepresented classes don't have e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
